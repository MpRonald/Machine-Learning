{
  "cells":[
    {
      "cell_type":"markdown",
      "source":[
        "# Resolvendo problemas de regressão no aprendizado de máquina"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Os algoritmos de aprendizado de máquina podem ser categorizados principalmente em dois tipos: algoritmos de aprendizado <b>supervisionado<\/b> e algoritmos de aprendizado <b>não supervisionado.<\/b>\n",
        "\n",
        "Algoritmos de aprendizado de máquina supervisionado são aqueles algoritmos em que o conjunto de dados de entrada e a saída correspondente ou previsão real estão disponíveis, e os algoritmos tentam encontrar a relação entre as entradas e saídas.\n",
        "\n",
        "Em algoritmos de aprendizado de máquina não supervisionados, no entanto, os verdadeiros rótulos para as saídas não são conhecidos. Em vez disso, os algoritmos tentam encontrar padrões semelhantes nos dados. Os algoritmos de agrupamento são um exemplo típico de aprendizagem não supervisionada.\n",
        "\n",
        "Os algoritmos de aprendizagem supervisionada são divididos em dois tipos: <b>algoritmos de regressão e algoritmos de classificação<\/b>.\n",
        "\n",
        "Os algoritmos de regressão preveem um valor contínuo, por exemplo, o preço de uma casa, a pressão arterial de uma pessoa e a pontuação de um aluno em um exame específico. Os algoritmos de classificação, por outro lado, prevêem um valor discreto, como se um tumor é maligno ou não, se um aluno vai ser aprovado ou reprovado em um exame, etc."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Preparação de dados para problemas de regressão"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "sns.get_dataset_names ()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Para ler um conjunto de dados específico no dataframe do Pandas, passe o nome do conjunto de dados para o método load_dataset() da biblioteca Seaborn."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tips_df = sns.load_dataset(\"tips\")"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tips_df.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# da mesma forma podemos ler outro DF\n",
        "diamond_df = sns.load_dataset(\"diamonds\")\n",
        "diamond_df.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Dividindo dados em recursos e rótulos\n",
        "Como primeira etapa, dividimos os dados em conjuntos de recursos e rótulos. Nosso conjunto de rótulos consiste em valores da coluna “dica”, enquanto o conjunto de recursos consiste em valores das colunas restantes. O script a seguir divide os dados em conjuntos de recursos e rótulos."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X = tips_df.drop(['tip'], axis=1)\n",
        "y = tips_df['tip']"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "y.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "## Conversão de dados categóricos em números\n",
        "Os algoritmos de aprendizado de máquina, em sua maioria, só funcionam com números. Portanto, é importante converter dados categóricos em um formato numérico.\n",
        "\n",
        "Nesse sentido, a primeira etapa é criar um conjunto de dados de todos os valores numéricos. Para fazer isso, elimine as colunas categóricas do conjunto de dados, conforme mostrado abaixo."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "numerical = X.drop(['sex', 'smoker', 'day', 'time'], axis=1)\n",
        "numerical.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Em seguida, você precisa criar um dataframe que contenha apenas colunas categóricas."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "categorical = X.filter(['sex', 'smoker', 'day', 'time'])\n",
        "categorical.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Uma das abordagens mais comuns para converter uma coluna categórica em numérica é por meio da codificação one-hot. Na codificação one-hot, para cada valor exclusivo nas colunas originais, uma nova coluna é criada. Por exemplo, para sexo, duas colunas: Feminino e Masculino, são criadas. Se a coluna de sexo original continha masculino, um 1 é adicionado na coluna Masculino recém-criada, enquanto 1 é adicionado na coluna Feminino recém-criada se a coluna de sexo original continha Feminino.\n",
        "\n",
        "No entanto, pode-se notar que realmente não precisamos de duas colunas. Uma única coluna, ou seja, Feminino, é suficiente, pois quando um cliente é feminino, podemos adicionar 1 na coluna Feminino, caso contrário, pode ser adicionado 1 nessa coluna. Portanto, precisamos de N-1 colunas com codificação one-hot para todos os N valores na coluna original.\n",
        "\n",
        "O script a seguir converte colunas categóricas em colunas com codificação one-hot usando o método pd.get_dummies ()."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import pandas as pd\n",
        "\n",
        "cat_nuemrical = pd.get_dummies(categorical, drop_first=True)\n",
        "cat_nuemrical.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "A etapa final é unir as colunas numéricas às colunas codificadas one-hot. Para fazer isso, você pode usar a função concat() da biblioteca Pandas, conforme mostrado abaixo:"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X = pd.concat([numerical, cat_nuemrical], axis=1)\n",
        "X.head()"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Divida os dados em conjuntos de treinamento e teste\n",
        "Depois de treinar um algoritmo de aprendizado de máquina, você precisa avaliá-lo para ver o desempenho dele em dados não vistos. Portanto, dividimos o conjunto de dados em dois conjuntos, ou seja, um conjunto de treinamento e um conjunto de teste. O conjunto de dados é treinado por meio do conjunto de treinamento e avaliado no conjunto de teste. Para dividir os dados em conjuntos de treinamento e teste, você pode usar a função train_test_split () da biblioteca Sklearn, conforme mostrado abaixo. O script a seguir divide os dados em um conjunto de treinamento de 80 por cento e um conjunto de teste de 20 por cento."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn. model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20,\n",
        "                                                    random_state=0)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Escalonamento \/ normalização de dados\n",
        "A etapa final (opcional) antes de os dados serem passados para algoritmos de aprendizado de máquina é dimensionar os dados. Você pode ver que algumas colunas do conjunto de dados contêm valores pequenos, enquanto as outras contêm valores muito grandes. É melhor converter todos os valores em uma escala uniforme. Para fazer isso, você pode usar a função StandardScaler() do módulo sklearn.preprocessing, conforme mostrado abaixo:"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Convertemos os dados em um formato que pode ser usado para treinar algoritmos de aprendizado de máquina para regressão da biblioteca Sklearn. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Regressão linear\n",
        "A regressão linear é um modelo linear que presume uma relação linear entre entradas e saídas e minimiza o custo do erro entre a saída prevista e real usando funções como erro absoluto médio entre diferentes pontos de dados.\n",
        "\n",
        "#### Por que usar o algoritmo de regressão linear?\n",
        "\n",
        "O algoritmo de floresta aleatório é particularmente útil quando:\n",
        "\n",
        "    1.A regressão linear é um algoritmo simples de implementar e facilmente interpretável.\n",
        "\n",
        "    2.Leva menos tempo de treinamento para treinar, mesmo para grandes conjuntos de dados.\n",
        "\n",
        "    3.Os coeficientes de regressão linear são fáceis de interpretar.\n",
        "\n",
        "#### Desvantagens do algoritmo de regressão linear\n",
        "\n",
        "A seguir estão as desvantagens do algoritmo de regressão linear:\n",
        "\n",
        "    1.O desempenho é facilmente afetado pela presença de outliers.\n",
        "\n",
        "    2.Pressupõe uma relação linear entre as variáveis dependentes e independentes, o que pode resultar em um aumento do erro.\n",
        "\n",
        "#### Implementando Regressão Linear com Sklearn\n",
        "\n",
        "Para implementar a regressão linear com Sklearn, você pode usar a classe LinearRegression do módulo sklearn.linear_model. Para treinar o algoritmo, os conjuntos de treinamento e teste, ou seja, X_train e X_test em nosso caso, são passados para o método <b>fit()<\/b> do objeto da classe LinearRegression. \n",
        "\n",
        "O conjunto de testes é passado para o método <b>predict()<\/b> da classe para fazer previsões. O processo de treinar e fazer previsões com o algoritmo de regressão linear é o seguinte:"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# treinando o algoritmo\n",
        "lin_reg = LinearRegression()\n",
        "regressor = lin_reg.fit(X_train, y_train)\n",
        "\n",
        "# fazendo as previsões\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Depois de treinar um modelo e fazer previsões no conjunto de teste, a próxima etapa é saber o quão bem seu modelo foi executado para fazer previsões no conjunto de teste desconhecido. "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Erro Médio Absoluto\n",
        "\n",
        "O erro absoluto médio (MAE) é calculado tomando a média do erro absoluto obtido subtraindo os valores reais dos valores previstos. A equação para calcular o MAE é:\n",
        "\n",
        "![image.png](attachment:.\/image_29.png)"
      ],
      "attachments":{
        ".\/image_29.png":{
          "image\/png":"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"
        }
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Erro Quadrático Médio\n",
        "\n",
        "O erro quadrático médio (MSE) é semelhante ao MAE. No entanto, o erro de cada registro é elevado ao quadrado no caso do MSE, a fim de punir os registros de dados com uma grande diferença entre os valores previstos e reais. A equação para calcular o erro quadrático médio é a seguinte:\n",
        "\n",
        "![image.png](attachment:.\/image_30.png)"
      ],
      "attachments":{
        ".\/image_30.png":{
          "image\/png":"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"
        }
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "### Raiz do erro quadrático médio\n",
        "\n",
        "O erro quadrático médio é simplesmente a raiz inferior do erro quadrático médio e pode ser calculado da seguinte forma:\n",
        "\n",
        "![image.png](attachment:.\/image_31.png)"
      ],
      "attachments":{
        ".\/image_31.png":{
          "image\/png":"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"
        }
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "met_abs =  metrics.mean_absolute_error(y_test, y_pred)\n",
        "met_sqrt = metrics.mean_squared_error(y_test, y_pred)\n",
        "met_sqrt_np = np.sqrt(metrics.mean_squared_error(y_test, y_pred))"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print('Mean Absolute Error: %.4f' % met_abs)\n",
        "print('Mean Squared Error: %.4f' % met_sqrt)\n",
        "print('Root Mean Squared Error: %.4f' % met_sqrt_np)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Leituras Adicionais - Regressão Linear\n",
        "Para estudar mais sobre regressão linear, verifique estes links:\n",
        "1. https:\/\/bit.ly\/2ZyCa49\n",
        "2. https:\/\/bit.ly\/2RmLhAp"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Regressão KNN\n",
        "KNN significa vizinhos K-mais próximos. KNN é um algoritmo de aprendizado preguiçoso, que se baseia em encontrar distâncias euclidianas entre diferentes pontos de dados.\n",
        "\n",
        "Por que usar o algoritmo KNN?\n",
        "\n",
        "### O KNN é particularmente útil quando:\n",
        "\n",
        "   1. O algoritmo KNN não assume nenhuma relação entre os recursos.\n",
        "\n",
        "   2. Útil para um conjunto de dados onde a localização dos dados é importante.\n",
        "\n",
        "   3. Só tem que ajustar o parâmetro K, que é o número de vizinhos mais próximos.\n",
        "\n",
        "   4. Nenhum treinamento é necessário, pois é um algoritmo de aprendizado preguiçoso.\n",
        "\n",
        "   5. Os sistemas de recomendação e a descoberta de semelhanças semânticas entre os documentos são as principais aplicações do algoritmo KNN.\n",
        "\n",
        "### Desvantagens do Algoritmo KNN\n",
        "\n",
        "A seguir estão as desvantagens do algoritmo KNN.\n",
        "\n",
        "   1. Você tem que encontrar o valor ideal para K, o que não é fácil.\n",
        "\n",
        "   2. Não é adequado para dados dimensionais muito elevados.\n",
        "\n",
        "Implementando o Algoritmo KNN com SKlearn\n",
        "\n",
        "Com o Sklearn, é extremamente fácil implementar a regressão KNN. Para fazer isso, você pode usar a classe KNeighborsRegressor. O processo de treinamento e teste é igual à regressão linear. Para treinamento, você precisa chamar o método fit(), e para teste, você precisa chamar o método predict().\n",
        "\n",
        "O script a seguir mostra o processo de treinamento, teste e avaliação do algoritmo de regressão KNN para prever os valores da coluna de dicas do conjunto de dados Dicas."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "KNN_reg = KNeighborsRegressor(n_neighbors=5)\n",
        "regressor = KNN_reg.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "met_abs =  metrics.mean_absolute_error(y_test, y_pred)\n",
        "met_sqrt = metrics.mean_squared_error(y_test, y_pred)\n",
        "met_sqrt_np = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print('Mean Absolute Error: %.4f' % met_abs)\n",
        "print('Mean Squared Error: %.4f' % met_sqrt)\n",
        "print('Root Mean Squared Error: %.4f' % met_sqrt_np)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Leituras adicionais - Regressão KNN\n",
        "Para estudar mais sobre a regressão KNN, verifique estes links:\n",
        "1. https:\/\/bit.ly\/35sIu0M\n",
        "2. https:\/\/bit.ly\/33r2Zbq"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Regressão Florestal Aleatória\n",
        "A floresta aleatória é um algoritmo baseado em árvore que converte recursos em nós de árvore e, em seguida, usa a perda de entropia para fazer previsões.\n",
        "\n",
        "Por que usar algoritmos de floresta aleatória?\n",
        "\n",
        "### Algoritmos de floresta aleatórios são particularmente úteis quando:\n",
        "\n",
        "   1. Você tem muitos dados ausentes ou um conjunto de dados desequilibrado.\n",
        "\n",
        "   2. Com um grande número de árvores, você pode evitar o sobreajuste durante o treinamento. O overfitting ocorre quando os modelos de aprendizado de máquina apresentam melhor desempenho no conjunto de treinamento, mas pior no conjunto de teste.\n",
        "\n",
        "   3. O algoritmo de floresta aleatório pode ser usado quando você tem dados dimensionais muito altos.\n",
        "\n",
        "   4. Por meio da validação cruzada, o algoritmo de floresta aleatório pode retornar maior precisão.\n",
        "\n",
        "   5. O algoritmo de floresta aleatória pode resolver tarefas de classificação e regressão e encontra sua aplicação em uma variedade de tarefas, desde detecção de fraude de cartão de crédito, previsão do mercado de ações e localização de transações online fraudulentas.\n",
        "\n",
        "### Desvantagens dos algoritmos de floresta aleatória\n",
        "\n",
        "Existem duas desvantagens principais nos algoritmos de floresta aleatória:\n",
        "\n",
        "   1. Usar um grande número de árvores pode tornar o algoritmo mais lento.\n",
        "\n",
        "   2. O algoritmo de floresta aleatória é um algoritmo preditivo, que pode apenas prever o futuro e não pode explicar o que aconteceu no passado usando o conjunto de dados.\n",
        "\n",
        "Implementando o Random Forest Regressor usando Sklearn\n",
        "\n",
        "A classe RandomForestRegressor do módulo Sklearn.ensemble pode ser usada para implementar algoritmos de regressor de floresta aleatório, conforme mostrado abaixo."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "# treinando o algoritmo\n",
        "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
        "regressor = rf_reg.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# avaliando modelo\n",
        "met_abs =  metrics.mean_absolute_error(y_test, y_pred)\n",
        "met_sqrt = metrics.mean_squared_error(y_test, y_pred)\n",
        "met_sqrt_np = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print('Mean Absolute Error: %.4f' % met_abs)\n",
        "print('Mean Squared Error: %.4f' % met_sqrt)\n",
        "print('Root Mean Squared Error: %.4f' % met_sqrt_np)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Leituras adicionais - Regressão florestal aleatória\n",
        "Para estudar mais sobre a regressão florestal aleatória, verifique estes links:\n",
        "1. https:\/\/bit.ly\/3bRkKEy\n",
        "2. https:\/\/bit.ly\/35u3BzH"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Support Vector Regression"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "A máquina de vetores de suporte é de classificação, bem como algoritmos de regressão, que minimizam o erro entre as previsões reais e as previsões previstas, maximizando a distância entre os hiperplanos que contêm dados para vários registros.\n",
        "\n",
        "### Por que usar algoritmos SVR?\n",
        "\n",
        "Support Vector Regression é uma variante da máquina de vetores de suporte (SVM) para regressão. O SVM tem os seguintes usos.\n",
        "\n",
        "   1. Ele pode ser usado para realizar regressão ou classificação com dados dimensionais elevados.\n",
        "\n",
        "   2. Com o truque do kernel, o SVM é capaz de aplicar regressão e classificação a conjuntos de dados não lineares.\n",
        "\n",
        "   3. Os algoritmos SVM são comumente usados ​​para classificação ordinal ou regressão, e é por isso que são comumente conhecidos como algoritmos de classificação.\n",
        "\n",
        "### Desvantagens dos algoritmos SVR\n",
        "\n",
        "Existem três desvantagens principais dos algoritmos SVR:\n",
        "\n",
        "   1. Muitos parâmetros a serem otimizados para obter o melhor desempenho.\n",
        "\n",
        "   2. O treinamento pode demorar muito em grandes conjuntos de dados.\n",
        "\n",
        "   3. Produz resultados ruins se o número de recursos for maior do que o número de registros em um conjunto de dados.\n",
        "\n",
        "Implementando SVR usando Sklearn\n",
        "\n",
        "Com a biblioteca Sklearn, você pode usar a classe SVM para implementar algoritmos de regressão de vetor de suporte, conforme mostrado abaixo."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# treinando modelo\n",
        "svm_reg = svm.SVR()\n",
        "regressor = svm_reg.fit(X_train, y_train)\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "\n",
        "# testando modelo\n",
        "met_abs =  metrics.mean_absolute_error(y_test, y_pred)\n",
        "met_sqrt = metrics.mean_squared_error(y_test, y_pred)\n",
        "met_sqrt_np = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
        "\n",
        "print('Mean Absolute Error: %.4f' % met_abs)\n",
        "print('Mean Squared Error: %.4f' % met_sqrt)\n",
        "print('Root Mean Squared Error: %.4f' % met_sqrt_np)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Leituras adicionais - Regressão de vetores de suporte\n",
        "Para estudar mais sobre a regressão do vetor de suporte, verifique estes links:\n",
        "1. https:\/\/bit.ly\/3bRACH9\n",
        "2. https:\/\/bit.ly\/3mg5PZG"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Validação cruzada K Fold\n",
        "Anteriormente, dividimos os dados em um conjunto de treinamento de 80 por cento e um conjunto de teste de 20 por cento. No entanto, isso significa que apenas 20 por cento dos dados são usados para teste e que 20 por cento dos dados nunca são usados para treinamento.\n",
        "\n",
        "Para resultados mais estáveis, é recomendado que todas as partes do conjunto de dados sejam usadas pelo menos uma vez para treinamento e uma vez para teste. A técnica de validação cruzada K-Fold pode ser usada para fazer isso. Com a validação cruzada K-fold, os dados são divididos em K partes. Os experimentos também são realizados para peças K. Em cada experimento, as partes K-1 são usadas para treinamento e a parte Kth é usada para teste.\n",
        "\n",
        "Por exemplo, na validação cruzada de 5 vezes, os dados são divididos em cinco partes iguais, por exemplo, K1, K2, K3, K4 e K5. Na primeira iteração, K1-K4 são usados para treinamento, enquanto K5 é usado para teste. No segundo teste, K1, K2, K3 e K5 são usados para treinamento e K4 é usado para teste. Desta forma, cada parte é usada pelo menos uma vez para teste e uma vez para treinamento.\n",
        "\n",
        "Você pode usar a função cross_val_score () do sklearn. Módulo model_selection para realizar validação cruzada conforme mostrado abaixo:"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "print((cross_val_score (regressor, X, y, cv = 5,\n",
        "                        scoring ='neg_mean_absolute_error')))"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Fazendo previsões em um único registro\n",
        "Nas seções anteriores, você viu como fazer previsões em um conjunto de teste completo. Nesta seção, você verá como fazer uma previsão usando um único registro como entrada.\n",
        "\n",
        "Vamos escolher o 100 º registro de nosso conjunto de dados."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tips_df.loc [100]"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tips_df.loc [50]"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "tips_df.loc [25]"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Vamos tentar prever o valor da ponta do 100º, 50º, 25º de forma independente e vamos compara-lo registro usando o algoritmo regressor Floresta aleatória e ver o que a saída que temos. Veja o script abaixo:\n",
        "\n",
        "Observe que você precisa dimensionar seu único registro antes que ele possa ser usado como entrada para seu algoritmo de aprendizado de máquina."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
        "regressor = rf_reg.fit(X_train, y_train)\n",
        "\n",
        "single_record_100 = sc.transform(X.values[100].reshape(1,-1))\n",
        "predict_tip = regressor.predict(single_record_100)\n",
        "\n",
        "single_record_50 = sc.transform(X.values[50].reshape(1,-1))\n",
        "predict_tip = regressor.predict(single_record_50)\n",
        "\n",
        "single_record_25 = sc.transform(X.values[25].reshape(1,-1))\n",
        "predict_tip = regressor.predict(single_record_25)\n",
        "\n",
        "print(f'Single Record 100: {single_record_100}\\n')\n",
        "print(f'Single Record 50: {single_record_50}\\n')\n",
        "print(f'Single Record 25: {single_record_25}\\n')"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# vamos transformar em DF para melhor vizualização\n",
        "sg100 = pd.DataFrame(single_record_100, index=['test_100'])\n",
        "sg50 = pd.DataFrame(single_record_50, index=['test_50'])\n",
        "sg25 = pd.DataFrame(single_record_25, index=['test_25'])"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sg100"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sg50"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sg25"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# concatenando DFs\n",
        "conc = [sg100, sg50, sg25]\n",
        "sg_dfs = pd.concat(conc)\n",
        "sg_dfs"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# renomeando colunas\n",
        "sg_dfs = sg_dfs.rename(columns= {0: 'test_01',\n",
        "                      1 : 'test_02',\n",
        "                      2 : 'test_03',\n",
        "                      3 : 'test_04',\n",
        "                      4 : 'test_05',\n",
        "                      5 : 'test_06',\n",
        "                      6 : 'test_07',\n",
        "                      7 : 'test_08'})"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sg_dfs"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf_reg = RandomForestRegressor (random_state = 42, n_estimators = 500)\n",
        "regressor = rf_reg.fit (X_train, y_train)\n",
        "single_record = sc.transform (X.values[100].reshape (1, -1))\n",
        "predicted_tip = regressor.predict (single_record)\n",
        "\n",
        "print(predicted_tip)"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "rf_reg = RandomForestRegressor(random_state=42, n_estimators=500)\n",
        "regressor = rf_reg.fit(X_train, y_train)\n",
        "\n",
        "single_record_100 = sc.transform(X.values[100].reshape(1,-1))\n",
        "predict_tip_100 = regressor.predict(single_record_100)\n",
        "\n",
        "single_record_50 = sc.transform(X.values[50].reshape(1,-1))\n",
        "predict_tip_50 = regressor.predict(single_record_50)\n",
        "\n",
        "single_record_25 = sc.transform(X.values[25].reshape(1,-1))\n",
        "predict_tip_25 = regressor.predict(single_record_25)\n",
        "\n",
        "print(f'Pedict Tip 100: {predict_tip_100}\\n')\n",
        "print(f'Predict Tip 50: {predict_tip_50}\\n')\n",
        "print(f'Predict Tip 25: {predict_tip_25}\\n')"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "sg_list = [[predict_tip_100, predict_tip_50, predict_tip_25]]\n",
        "sg_list"
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        
      ],
      "execution_count":null,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}