{
  "cells":[
    {
      "cell_type":"code",
      "source":[
        "import torch"
      ],
      "execution_count":1,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print(torch.__version__)"
      ],
      "execution_count":2,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "1.9.1+cpu\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Tensores PyTorch\n",
        "Tensores são os tipos de dados fundamentais do PyTorch. Um tensor é uma matriz multidimensional semelhante aos ndarrays de NumPy:\n",
        "\n",
        "* Um escalar pode ser representado como um tensor de dimensão zero.\n",
        "* Um vetor pode ser representado como um tensor unidimensional.\n",
        "* Uma matriz bidimensional pode ser representada como um tensor bidimensional.\n",
        "* Uma matriz multidimensional pode ser representada como um tensor multidimensional."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# incializando um tensor\n",
        "x = torch.tensor([[1,2]])\n",
        "y = torch.tensor([[1],[2]])"
      ],
      "execution_count":3,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# acessando a forma e o tipo do dado;\n",
        "print(f'Dimensão de x: {x.shape}\\nDimensão de y: {y.shape}\\n')\n",
        "print(f'Tipo de dado de x: {x.dtype}\\nTipo de dado de y: {y.type}')"
      ],
      "execution_count":5,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Dimensão de x: torch.Size([1, 2])\n",
            "Dimensão de y: torch.Size([2, 1])\n",
            "\n",
            "Tipo de dado de x: torch.int64\n",
            "Tipo de dado de y: <built-in method type of Tensor object at 0x7f2ed6792140>\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# verificando um tensor do tipo booleano\n",
        "x = torch.tensor([False, True])\n",
        "y = torch.tensor(([False, True, 1, 2.0]))\n",
        "# se tivermos um tensor somente booleano teremos uma saida diferente se a lista conter outros\n",
        "# tipos de dados, os valores serão convertidos em 0 -> False e 1 -> True\n",
        "print(f'Somente booleanos: {x}')\n",
        "print(f'Diversos tipos de dados: {y}')"
      ],
      "execution_count":6,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Somente booleanos: tensor([False,  True])\n",
            "Diversos tipos de dados: tensor([0., 1., 1., 2.])\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# gerando um tensor de zeros 3 x 4\n",
        "torch.zeros((3,4))"
      ],
      "execution_count":7,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# gerando um tensor de uns 3 x 4\n",
        "torch.ones((3,4))"
      ],
      "execution_count":8,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# gerando um tensor aleatorio 3 x 4, com valor minimo 0 e maximo 10\n",
        "torch.randint(low=0, high=10, size=(3,4))"
      ],
      "execution_count":9,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[3, 7, 2, 0],\n",
              "        [2, 4, 1, 6],\n",
              "        [1, 1, 1, 3]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# gerando numeros aleatorios entre 0 e 1\n",
        "torch.rand(3,4)"
      ],
      "execution_count":10,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[0.3348, 0.5092, 0.1224, 0.9948],\n",
              "        [0.1736, 0.1740, 0.1960, 0.0311],\n",
              "        [0.5823, 0.8016, 0.4792, 0.4072]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# gerando numeros de uma distribuição normal\n",
        "torch.randn((3,4))"
      ],
      "execution_count":11,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[ 0.5156,  1.4579, -0.3109,  0.1952],\n",
              "        [-0.6684, -1.1528,  0.3089, -0.2741],\n",
              "        [ 0.4389, -0.5326, -1.0334, -0.9158]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# convertendo uma matriz Numpy em um tensor\n",
        "import numpy as np\n",
        "x = np.array([[10,20,30],[2,3,4]])\n",
        "y = torch.tensor(x)\n",
        "print(f'Tipo de dado: {type(x)}, tipo anterior convertido {type(y)}')"
      ],
      "execution_count":12,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Tipo de dado: <class 'numpy.ndarray'>, tipo anterior convertido <class 'torch.Tensor'>\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Operações com tensores"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x = torch.tensor([[1,2,3,4], [5,6,7,8]])\n",
        "print(f'Tensor com valores iniciais: {x}')\n",
        "print(f'Tensor com valores multiplicados por 10: {x*10}')"
      ],
      "execution_count":13,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Tensor com valores iniciais: tensor([[1, 2, 3, 4],\n",
            "        [5, 6, 7, 8]])\n",
            "Tensor com valores multiplicados por 10: tensor([[10, 20, 30, 40],\n",
            "        [50, 60, 70, 80]])\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# adicionando valor ao tensor\n",
        "x.add(10)"
      ],
      "execution_count":15,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[11, 12, 13, 14],\n",
              "        [15, 16, 17, 18]])"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# concatenando tensores\n",
        "x = torch.randn(10,10,10)\n",
        "z = torch.cat([x,x], axis=0)\n",
        "print('Eixo cat axis 0: ', x.shape, z.shape)\n",
        "\n",
        "z = torch.cat([x,x], axis=1)\n",
        "print('Eixo cat axis 1: ', x.shape, z.shape)\n",
        "\n",
        "z = torch.cat([x,x], axis=2)\n",
        "print('Eixo cat axis 2: ', x.shape, z.shape)"
      ],
      "execution_count":16,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Eixo cat axis 0:  torch.Size([10, 10, 10]) torch.Size([20, 10, 10])\n",
            "Eixo cat axis 1:  torch.Size([10, 10, 10]) torch.Size([10, 20, 10])\n",
            "Eixo cat axis 2:  torch.Size([10, 10, 10]) torch.Size([10, 10, 20])\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x = torch.arange(25).reshape(5,5)\n",
        "print(x)\n",
        "print(f'Maior valor no tensor: {x.max()}')\n",
        "print(f'Menor valor no tensor: {x.min()}')"
      ],
      "execution_count":17,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "tensor([[ 0,  1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8,  9],\n",
            "        [10, 11, 12, 13, 14],\n",
            "        [15, 16, 17, 18, 19],\n",
            "        [20, 21, 22, 23, 24]])\n",
            "Maior valor no tensor: 24\n",
            "Menor valor no tensor: 0\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# extraindo os maiores valores do tensor e sua localização\/indice (linha da matriz)\n",
        "x.max(dim=0)"
      ],
      "execution_count":18,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "torch.return_types.max(\n",
              "values=tensor([20, 21, 22, 23, 24]),\n",
              "indices=tensor([4, 4, 4, 4, 4]))"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "É importante saber que você pode fazer quase todas as operações do NumPy no PyTorch com quase a mesma sintaxe do NumPy. Operações matemáticas padrão, tais como abs, add, argsort, ceil, floor, sin, cos, tan, cumsum, cumprod, diag, eig, exp, log, log2, log10, mean, median, mode, resize, round, sigmoid, softmax, square, sqrt, svd, e transpose, para citar alguns, pode ser diretamente chamado em qualquer tensor com ou sem eixos onde aplicável. Você sempre pode executar dir(torch.Tensor) para ver todos os métodos possíveis para um tensor de tocha ehelp(torch.Tensor.<method>) para consultar a ajuda e a documentação oficial desse método."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Gradientes automáticos de objetos tensores"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definindo um gradiente e um tensor\n",
        "x = torch.tensor([[2.,-1.],[1.,1.]], requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count":20,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "tensor([[ 2., -1.],\n",
            "        [ 1.,  1.]], requires_grad=True)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "No código anterior, o requires_grad parâmetro especifica que o gradiente deve ser calculado para o objeto tensor."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Construindo uma rede neural usando PyTorch\n",
        "No capítulo anterior, aprendemos como construir uma rede neural do zero, onde os componentes de uma rede neural são os seguintes:\n",
        "\n",
        "* O número de camadas ocultas\n",
        "* O número de unidades em uma camada oculta\n",
        "* Funções de ativação realizadas nas várias camadas\n",
        "* A função de perda que tentamos otimizar para\n",
        "* A taxa de aprendizagem associada à rede neural\n",
        "* O tamanho do lote de dados aproveitado para construir a rede neural\n",
        "* O número de épocas de propagação para frente e para trás"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import torch\n",
        "x = torch.rand(1, 6400)\n",
        "y = torch.rand(6400, 5000)"
      ],
      "execution_count":21,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count":22,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x, y = x.to(device), y.to(device)"
      ],
      "execution_count":23,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "%timeit z=(x@y)"
      ],
      "execution_count":24,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "7.48 ms ± 1.89 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x, y = x.cpu(), y.cpu()\n",
        "%timeit z=(x@y)"
      ],
      "execution_count":25,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "6.56 ms ± 50.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import numpy as np\n",
        "x = np.random.random((1, 6400))\n",
        "y = np.random.random((6400, 5000))\n",
        "%timeit z = np.matmul(x,y)"
      ],
      "execution_count":26,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "13.9 ms ± 155 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definindo valores de entrada e saida\n",
        "x = [[1,2],[3,4],[5,6],[7,8]]\n",
        "y = [[3],[7],[11],[15]]"
      ],
      "execution_count":27,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Observe que na inicialização da variável de entrada e saída anterior, a entrada e a saída são uma lista de listas em que a soma dos valores na lista de entrada são os valores na lista de saída."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# realizando um cast nas entradas\n",
        "X = torch.tensor(x).float()\n",
        "Y = torch.tensor(y).float()"
      ],
      "execution_count":28,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)"
      ],
      "execution_count":29,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definindo a arquitetura da rede neural\n",
        "import torch.nn as nn"
      ],
      "execution_count":30,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# criando uma classe para compor a arquitetura de modelo\n",
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # chamamos o super para que a classe herde de nn\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8) # camada linear\n",
        "        self.hidden_layer_activation = nn.ReLU() # camada de ativação\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1) # camada linear\n",
        "        # print(nn.Linear)"
      ],
      "execution_count":31,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "print (nn.Linear ( 2 , 7 ))"
      ],
      "execution_count":32,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Linear(in_features=2, out_features=7, bias=True)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def forward (self, x): \n",
        "    x = self.input_to_hidden_layer (x) \n",
        "    x = self.hidden_layer_activation (x) \n",
        "    x = self.hidden_to_output_layer (x) \n",
        "    return x"
      ],
      "execution_count":33,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# criando uma instancia\n",
        "mynet = MyNeuralNet().to(device)"
      ],
      "execution_count":34,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "mynet.input_to_hidden_layer.weight"
      ],
      "execution_count":35,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "Parameter containing:\n",
              "tensor([[ 0.0598,  0.2959],\n",
              "        [-0.2733,  0.5146],\n",
              "        [ 0.5927, -0.2879],\n",
              "        [-0.1242, -0.6149],\n",
              "        [-0.3833,  0.1826],\n",
              "        [-0.3827, -0.0704],\n",
              "        [-0.1510, -0.3834],\n",
              "        [ 0.0751, -0.4923]], requires_grad=True)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# Todos os parâmetros de uma rede neural podem ser obtidos usando o seguinte código:\n",
        "mynet.parameters()"
      ],
      "execution_count":36,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "<generator object Module.parameters at 0x7f2ed67b26d0>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "for i in mynet.parameters():\n",
        "    print(i)"
      ],
      "execution_count":37,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Parameter containing:\n",
            "tensor([[ 0.0598,  0.2959],\n",
            "        [-0.2733,  0.5146],\n",
            "        [ 0.5927, -0.2879],\n",
            "        [-0.1242, -0.6149],\n",
            "        [-0.3833,  0.1826],\n",
            "        [-0.3827, -0.0704],\n",
            "        [-0.1510, -0.3834],\n",
            "        [ 0.0751, -0.4923]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.2390,  0.1024, -0.5023,  0.2467, -0.2507, -0.1084, -0.3090, -0.3910],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0892,  0.1432, -0.1508,  0.2059,  0.1611, -0.2687,  0.3175,  0.1244]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2772], requires_grad=True)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Conjunto de dados, DataLoader e tamanho do lote"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count":38,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x = [[1 , 2], [3 , 4], [5 , 6], [7 , 8]] \n",
        "y = [[ 3 ], [ 7 ], [ 11 ], [ 15 ]]"
      ],
      "execution_count":39,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "X = torch.tensor (x).float () \n",
        "Y = torch.tensor (y).float ()"
      ],
      "execution_count":40,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "device = 'cuda' if torch.cuda.is_available () else 'cpu'\n",
        "X = X.to(device) \n",
        "Y = Y.to(device)  "
      ],
      "execution_count":41,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# instanciando uma classe dataset\n",
        "class Mydataset(Dataset):\n",
        "    \"\"\"Definindo metodo que pega pares de entrada e saida\n",
        "    e converte em objetos flutuantes\"\"\"\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x).float()\n",
        "        self.y = torch.tensor(y).float()\n",
        "\n",
        "    \"\"\"Especifica o comprimento do conjunto de entrada de dados\"\"\"\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    \"\"\"Método usado para buscar uma linha específica\"\"\"\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]"
      ],
      "execution_count":43,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# criando uma instancia\n",
        "ds = Mydataset(X, Y)"
      ],
      "execution_count":44,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "<ipython-input-43-3fcc0a0d21e2>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(x).float()\n",
            "<ipython-input-43-3fcc0a0d21e2>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y).float()\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ],
      "execution_count":45,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# abaixo um codigo ilustrativo para impressao de lotes de entrada e saida de dados\n",
        "for x, y in dl:\n",
        "    print(x, y)"
      ],
      "execution_count":46,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "tensor([[3., 4.],\n",
            "        [7., 8.]]) tensor([[ 7.],\n",
            "        [15.]])\n",
            "tensor([[5., 6.],\n",
            "        [1., 2.]]) tensor([[11.],\n",
            "        [ 3.]])\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Observe que o código anterior resultou em dois conjuntos de pares de entrada-saída, pois havia um total de quatro pontos de dados no conjunto de dados original, enquanto o tamanho do lote especificado era 2."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definindo uma classe de rede\n",
        "class MyNeuralNet (nn.Module): \n",
        "    def __init__(self): \n",
        "        super().__init__() \n",
        "        self.input_to_hidden_layer = nn.Linear (2,8) \n",
        "        self.hidden_layer_activation = nn.ReLU () \n",
        "        self.hidden_to_output_layer = nn.Linear (8,1) \n",
        "    def forward (self, x): \n",
        "        x = self.input_to_hidden_layer (x) \n",
        "        x = self.hidden_layer_activation (x) \n",
        "        x = self.hidden_to_output_layer (x) \n",
        "        return x"
      ],
      "execution_count":47,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# definindo o modelo do objeto\n",
        "mynet = MyNeuralNet().to(device)\n",
        "loss_func = nn.MSELoss()\n",
        "from torch.optim import SGD\n",
        "opt = SGD(mynet.parameters(), lr = 0.001)"
      ],
      "execution_count":48,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# loop pelos lotes de pontos de dados para minimizar o valor de perda\n",
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "    for data in dl:\n",
        "        x, y = data\n",
        "        opt.zero_grad()\n",
        "        loss_value = loss_func(mynet(x), y)\n",
        "        loss_value.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count":49,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "0.08872175216674805\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Previsão de novos pontos de dados"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# criando novo ponto de dados para teste de modelo\n",
        "val_x = [[10,11]]"
      ],
      "execution_count":50,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# realizando um cast nos pontos de dados\n",
        "val_x = torch.tensor(val_x).float().to(device)"
      ],
      "execution_count":51,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# passando o objeto tensor pela rede neural treinada\n",
        "mynet(val_x)"
      ],
      "execution_count":52,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[20.4103]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Implementando uma função de perda personalizada\n",
        "Em certos casos, podemos ter que implementar uma função de perda customizada para o problema que estamos resolvendo - especialmente em casos de uso complexos envolvendo detecção de objetos \/ redes adversas geradoras ( GANs ). O PyTorch fornece as funcionalidades para construirmos uma função de perda personalizada, escrevendo uma função nossa."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "x = [[1,2],[3,4],[5,6],[7,8]]\n",
        "y = [[3],[7],[11],[15]]\n",
        "\n",
        "X = torch.tensor(x).float()\n",
        "Y = torch.tensor(y).float()\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "X = X.to(device)\n",
        "Y = Y.to(device) \n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self,x,y):\n",
        "        self.x = torch.tensor(x).float()\n",
        "        self.y = torch.tensor(y).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]\n",
        "\n",
        "class MyNeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
        "        self.hidden_layer_activation = nn.ReLU()\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
        "\n",
        "    def foward(self, x):\n",
        "        x = self.input_to_hidden_layer(x)\n",
        "        x = self.hidden_layer_activation(x)\n",
        "        x = self.hidden_to_output_layer(x)\n",
        "        return x"
      ],
      "execution_count":53,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "ds = MyDataset(X, Y)\n",
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ],
      "execution_count":54,
      "outputs":[
        {
          "name":"stderr",
          "text":[
            "<ipython-input-53-9ede29fde196>:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.x = torch.tensor(x).float()\n",
            "<ipython-input-53-9ede29fde196>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.y = torch.tensor(y).float()\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "mynet = MyNeuralNet().to(device)"
      ],
      "execution_count":55,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "def my_mean_squared_error(_y, y):\n",
        "    loss = (_y-y)**2\n",
        "    loss = loss.mean()\n",
        "    return loss"
      ],
      "execution_count":56,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "loss_func = nn.MSELoss()\n",
        "loss_value = loss_func(mynet(X),Y)\n",
        "print(loss_value)"
      ],
      "execution_count":57,
      "outputs":[
        {
          "ename":"NotImplementedError",
          "evalue":"NotImplementedError: ",
          "traceback":[
            "\u001b[0;31m---------------------------------------------------------------------------",
            "Traceback (most recent call last)",
            "    at line 2 in <module>",
            "NotImplementedError: "
          ],
          "output_type":"error"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "my_mean_squared_error(mynet(X),Y)"
      ],
      "execution_count":58,
      "outputs":[
        {
          "ename":"NotImplementedError",
          "evalue":"NotImplementedError: ",
          "traceback":[
            "\u001b[0;31m---------------------------------------------------------------------------",
            "Traceback (most recent call last)",
            "    at line 1 in <module>",
            "NotImplementedError: "
          ],
          "output_type":"error"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "input_to_hidden = mynet.input_to_hidden_layer(X) \n",
        "hidden_activation = mynet.hidden_layer_activation (input_to_hidden) \n",
        "print(hidden_activation)"
      ],
      "execution_count":59,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "tensor([[0.3476, 0.2213, 0.7853, 0.1512, 0.0000, 0.0000, 1.5317, 0.0000],\n",
            "        [1.2601, 0.0000, 0.7816, 0.8359, 0.0000, 0.0000, 3.4046, 0.0000],\n",
            "        [2.1727, 0.0000, 0.7779, 1.5205, 0.0000, 0.0000, 5.2775, 0.0000],\n",
            "        [3.0853, 0.0000, 0.7742, 2.2051, 0.0000, 0.0000, 7.1503, 0.0000]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Observe que tivemos que chamar a input_to_hidden_layerativação antes de chamar, hidden_layer_activationpois a saída de input_to_hidden_layeré a entrada para a hidden_layer_activationcamada."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "class Neuralnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_to_hidden_layer = nn.Linear(2,8)\n",
        "        self.hidden_layer_activation = nn.ReLU()\n",
        "        self.hidden_to_output_layer = nn.Linear(8,1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        hidden1 = self.input_to_hidden_layer(x)\n",
        "        hidden2 = self.hidden_layer_activation(hidden1)\n",
        "        output = self.hidden_to_output_layer(hidden2)\n",
        "        return output, hidden2"
      ],
      "execution_count":65,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Usando um método sequencial para construir uma rede neural"
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "x = [[ 1 , 2 ], [ 3 , 4 ], [ 5 , 6 ], [ 7 , 8 ]] \n",
        "y = [[ 3 ], [ 7 ], [ 11 ], [ 15 ]]"
      ],
      "execution_count":76,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count":77,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x).float().to(device)\n",
        "        self.y = torch.tensor(y).float().to(device)\n",
        "    def __getitem__(self, ix):\n",
        "        return self.x[ix], self.y[ix]\n",
        "    def __len__(self): \n",
        "        return len(self.x)"
      ],
      "execution_count":78,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "ds = MyDataset(x, y)\n",
        "dl = DataLoader(ds, batch_size=2, shuffle=True)"
      ],
      "execution_count":79,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model = nn.Sequential(nn.Linear(2, 8), nn.ReLU(), nn.Linear(8, 1)).to(device)"
      ],
      "execution_count":80,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# instalando o package torch_summary\n",
        "# !pip install torch_summary"
      ],
      "execution_count":81,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "Collecting torch_summary\r\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\r\n",
            "Installing collected packages: torch-summary\r\n",
            "Successfully installed torch-summary-1.4.5\r\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "from torchsummary import summary\n",
        "summary(model, torch.zeros(1,2))"
      ],
      "execution_count":84,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Linear: 1-1                            [-1, 8]                   24\n",
            "├─ReLU: 1-2                              [-1, 8]                   --\n",
            "├─Linear: 1-3                            [-1, 1]                   9\n",
            "==========================================================================================\n",
            "Total params: 33\n",
            "Trainable params: 33\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 0.00\n",
            "==========================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward\/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.00\n",
            "Estimated Total Size (MB): 0.00\n",
            "==========================================================================================\n"
          ],
          "output_type":"stream"
        },
        {
          "data":{
            "text\/plain":[
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Linear: 1-1                            [-1, 8]                   24\n",
              "├─ReLU: 1-2                              [-1, 8]                   --\n",
              "├─Linear: 1-3                            [-1, 1]                   9\n",
              "==========================================================================================\n",
              "Total params: 33\n",
              "Trainable params: 33\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward\/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "\"\"\"A seguir, definimos a função de perda ( loss_func) e o \n",
        "otimizador ( opt) e treinamos o modelo\"\"\"\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "from torch.optim import SGD\n",
        "opt = SGD(model.parameters(), lr = 0.001)\n",
        "import time\n",
        "loss_history = []\n",
        "start = time.time()\n",
        "for _ in range(50):\n",
        "    for ix, iy in dl:\n",
        "        opt.zero_grad()\n",
        "        loss_value = loss_func(model(ix),iy)\n",
        "        loss_value.backward()\n",
        "        opt.step()\n",
        "        loss_history.append(loss_value)\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count":85,
      "outputs":[
        {
          "name":"stdout",
          "text":[
            "0.05539441108703613\n"
          ],
          "output_type":"stream"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# agora que o modelo está treinado podemos prever os valores\n",
        "val = [[8 , 9], [10 ,11], [1.5, 2.5]]"
      ],
      "execution_count":90,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model(torch.tensor(val).float().to(device))"
      ],
      "execution_count":88,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "tensor([[16.5568],\n",
              "        [20.2641],\n",
              "        [ 4.4850]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Observe que a saída do código anterior, conforme mostrado no comentário, está próxima do esperado (que é a soma dos valores de entrada)."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# salvando\n",
        "torch.save(model.to('cpu').state_dict(), 'mymodel.pth')"
      ],
      "execution_count":91,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "# lendo o arquivo\n",
        "state_dict = torch.load ('mymodel.pth')"
      ],
      "execution_count":92,
      "outputs":[
        
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"code",
      "source":[
        "model.load_state_dict (state_dict)"
      ],
      "execution_count":93,
      "outputs":[
        {
          "data":{
            "text\/plain":[
              "<All keys matched successfully>"
            ]
          },
          "metadata":{
            
          },
          "output_type":"display_data"
        }
      ],
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "Se todos os nomes de peso estiverem presentes no modelo, você receberá uma mensagem dizendo que todas as chaves foram combinadas. Isso significa que podemos carregar nosso modelo do disco, para todos os fins, em qualquer máquina do mundo."
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        "# Attention\n",
        "Every codes here are book's Moder Computer vision with PyTorch<br>\n",
        "https:\/\/learning.oreilly.com\/library\/view\/modern-computer-vision\/9781839213472\/f1d61b2c-dbb8-43ac-ac4e-75941daecc4c.xhtml#uuid-7b6ca1ba-20ea-4326-a10f-61c46baa7103 "
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    },
    {
      "cell_type":"markdown",
      "source":[
        
      ],
      "attachments":{
        
      },
      "metadata":{
        
      }
    }
  ],
  "metadata":{
    
  },
  "nbformat":4,
  "nbformat_minor":0
}